{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KT Project1 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate N-Gram distance of candidate pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ngram_distance(str1, str2, n=2):\n",
    "    # add '#' in both the head and the tail\n",
    "    tmp = ' ' * (n-1)\n",
    "    str1 = tmp + str1 + tmp\n",
    "    str2 = tmp + str2 + tmp\n",
    "    set1 = set([str1[i:i+n] for i in range(len(str1)-(n-1))])\n",
    "    set2 = set([str2[i:i+n] for i in range(len(str2)-(n-1))])\n",
    "    setx = set1 & set2\n",
    "    len1 = len(set1)\n",
    "    len2 = len(set2)\n",
    "    lenx = len(setx)\n",
    "    num_dist = len1 + len2 - 2*lenx\n",
    "    num_sim = 1 - num_dist / (len1 + len2)\n",
    "    return num_dist, num_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getCandidatePairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidatePairs(_word, _prefixes, _suffixes):\n",
    "    # candidate pairs\n",
    "    candiPairs = {}\n",
    "    if (len(_word) == 4):\n",
    "        p = _word[:2]\n",
    "        s = _word[1:]\n",
    "#         print(p + \" \" + str(len(_prefixes[p])))\n",
    "#         print(s + \" \" + str(len(_suffixes[s])))\n",
    "        if ((p not in _prefixes) or (s not in _suffixes)):\n",
    "            return candiPairs\n",
    "        for i in _prefixes[p]:\n",
    "            # ignore those prefix words never appear\n",
    "            if (dictWithFreq[dictionary[i]] < 5): continue\n",
    "            # ignore those suffix words never appear\n",
    "            for j in _suffixes[s]:\n",
    "                if (dictWithFreq[dictionary[j]] < 5): continue\n",
    "                #the candidate pairs of the specific prefix and suffix\n",
    "                pair = str(i) + ' ' + str(j)\n",
    "                if (pair in candiPairs):\n",
    "                    candiPairs[pair][0] += 1\n",
    "                    candiPairs[pair][1].append(p + ' ' + s)\n",
    "                else:\n",
    "                    candiPairs[pair] = [1, [p + ' ' + s]]\n",
    "    else:\n",
    "        for i in range(len(_word) - 3):\n",
    "            if (i + 2 >= len(_word) - i): break\n",
    "            p = _word[:i + 2]\n",
    "            s = _word[i + 2:]\n",
    "            if ((p not in _prefixes) or (s not in _suffixes)): continue\n",
    "#             print(p + \" \" + str(len(_prefixes[p])))\n",
    "#             print(s + \" \" + str(len(_suffixes[s])))\n",
    "            for i in _prefixes[p]:\n",
    "                # ignore those prefix words never appear\n",
    "                if (dictWithFreq[dictionary[i]] < 5): continue\n",
    "                for j in _suffixes[s]:\n",
    "                    # ignore those suffix words never appear\n",
    "                    if (dictWithFreq[dictionary[j]] < 5): continue\n",
    "                    #the candidate pairs of the specific prefix and suffix\n",
    "                    pair = str(i) + ' ' + str(j)\n",
    "                    if (pair in candiPairs):\n",
    "                        candiPairs[pair][0] += 1\n",
    "                        candiPairs[pair][1].append(p + ' ' + s)\n",
    "                    else:\n",
    "                        candiPairs[pair] = [1, [p + ' ' + s]]\n",
    "    return candiPairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weithting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(theBlend, key, w1, pre, suf):\n",
    "    i1, i2 = key.split()\n",
    "    s1 = dictionary[int(i1)]\n",
    "    s2 = dictionary[int(i2)]\n",
    "    index = 0\n",
    "    w2 = 1 - w1\n",
    "    # Create Inverse Coining Blend by prefix word\n",
    "    for i in range(len(s1)):\n",
    "        if s1[i] in \"aeiou\":\n",
    "            if (suf[0] in \"aeiou\"):\n",
    "                index = i\n",
    "            else:\n",
    "                index = i + 1\n",
    "            break\n",
    "    icFromP = s1[:index] + suf\n",
    "    # Create Inverse Coining Blend by suffix word\n",
    "    for i in range(len(s2)):\n",
    "        if s2[i] in \"aeiou\":\n",
    "            if (pre[-1] in \"aeiou\"):\n",
    "                index = i + 1\n",
    "            else:\n",
    "                index = i\n",
    "            break\n",
    "    icFromS = pre + s2[index:]\n",
    "    return w1 * Ngram_distance(theBlend, icFromP, 4)[0] + w2 * Ngram_distance(theBlend, icFromS, 4)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDC(blendWord, prefixes, suffixes, w1):\n",
    "    topN = 1\n",
    "    candidates = getCandidatePairs(blendWord, prefixes, suffixes)\n",
    "    candidates_df = pd.DataFrame.from_dict(candidates, orient='index', columns = ['count', 'pre-suf']).reset_index().rename(columns = {'index': 'key'})\n",
    "    dc = []\n",
    "    for index, row in candidates_df.iterrows():\n",
    "        pre, suf = row[\"pre-suf\"][0].split()\n",
    "        dc.append(weight(blendWord, row.key, w1, pre, suf))\n",
    "        \n",
    "    candidates_df['dc'] = dc\n",
    "    pDC = (np.zeros(topN, dtype = np.int) - 1).tolist()\n",
    "    sDC = (np.zeros(topN, dtype = np.int) - 1).tolist()\n",
    "    pfWord = []\n",
    "    sfWord = []\n",
    "    pi = 0\n",
    "    si = 0\n",
    "    for index, row in candidates_df.sort_values(by=\"dc\", ascending=True).iterrows():\n",
    "        i1, i2 = row.key.split()\n",
    "        s1 = dictionary[int(i1)]\n",
    "        s2 = dictionary[int(i2)]\n",
    "        if (len(pfWord) < topN and s1 not in pfWord):\n",
    "            pfWord.append(s1)\n",
    "            pDC[pi] = row.dc\n",
    "            pi += 1;\n",
    "        if (len(sfWord) < topN and s2 not in sfWord):\n",
    "            sfWord.append(s2)\n",
    "            sDC[si] = row.dc\n",
    "            si += 1;\n",
    "        if (len(pfWord) == topN and len(sfWord) == topN):\n",
    "            break\n",
    "#     return pfWord, sfWord, pDC, sDC\n",
    "    return pDC[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getTopNSufComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def getTopNSufComponent(blendWord, prefixes, suffixes, topN, w1):\n",
    "    candidates = getCandidatePairs(blendWord, prefixes, suffixes)\n",
    "    candidates_df = pd.DataFrame.from_dict(candidates, orient='index', columns = ['count', 'pre-suf']).reset_index().rename(columns = {'index': 'key'})\n",
    "    scores = []\n",
    "    for index, row in candidates_df.iterrows():\n",
    "        pre, suf = row[\"pre-suf\"][0].split()\n",
    "        scores.append(weight(blendWord, row.key, w1, pre, suf))\n",
    "    candidates_df['score'] = scores\n",
    "    pfWord = set()\n",
    "    sfWord = set()\n",
    "    for x in candidates_df.sort_values(by=\"score\", ascending=True).key:\n",
    "        i1, i2 = x.split()\n",
    "        s1 = dictionary[int(i1)]\n",
    "        s2 = dictionary[int(i2)]\n",
    "        if (len(pfWord) < topN):\n",
    "            pfWord.add(s1)\n",
    "        if (len(sfWord) < topN):\n",
    "            sfWord.add(s2)\n",
    "        if (len(pfWord) == topN and len(sfWord) == topN):\n",
    "            break\n",
    "    return pfWord, sfWord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tweets and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "# Display progress logs on stdout\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "def readLabelData(path):\n",
    "    fo = open(path, \"r\")\n",
    "    data = fo.readlines();\n",
    "    fo.close()\n",
    "    res = []\n",
    "    for x in data:\n",
    "        x = x.rstrip('\\n')\n",
    "        id, tweet = x.split('\\t')\n",
    "        res.append([int(id), tweet])\n",
    "    return res\n",
    "\n",
    "def readTweets(path):\n",
    "    fo = open(path, \"r\")\n",
    "    data = fo.readlines();\n",
    "    fo.close()\n",
    "    res = []\n",
    "    for x in data:\n",
    "        x = x.rstrip('\\n')\n",
    "        res.append(x)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/tweets.txt\",\"rb\")\n",
    "tweets1 = []\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    else:\n",
    "        try:\n",
    "            #print(line.decode('utf8'))\n",
    "            tweets1.append(line.decode('utf8'))\n",
    "            #为了暴露出错误，最好此处不print\n",
    "        except:\n",
    "            continue\n",
    "#             print(str(line))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets2 = readTweets('data/tweets2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tweets3.txt', \n",
    "                 encoding=\"utf-8\",\n",
    "                 header=None, sep='\\t',\n",
    "                quoting=csv.QUOTE_NONE)\n",
    "# df = pd.DataFrame(data)\n",
    "df.columns = ['id', 'tweet']\n",
    "tweets3 = df.tweet.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426687"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets1 + tweets2 + tweets3\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df.columns = ['tweet']\n",
    "tweets_df['tweet'] = tweets_df['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "tweets_df['tweet'] = tweets_df['tweet'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stop = stopwords.words('english')\n",
    "# tweets_df['tweet'] = tweets_df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "# tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dictionary and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = readTweets('data/dict.txt')\n",
    "dictWithFreq = {}\n",
    "for word in dictionary:\n",
    "    dictWithFreq[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "for tweet in tweets_df.tweet:\n",
    "    tokens = TextBlob(tweet).words\n",
    "    for token in tokens:\n",
    "        if (token in dictWithFreq): dictWithFreq[token] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>97748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaa</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aah</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aahed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     key  count\n",
       "0      a  97748\n",
       "1     aa     44\n",
       "2    aaa     22\n",
       "3    aah     17\n",
       "4  aahed      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictWithFreq_df = pd.DataFrame.from_dict(dictWithFreq, orient='index', columns = ['count']).reset_index().rename(columns = {'index': 'key'})\n",
    "dictWithFreq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Candidate and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "c_df = pd.read_csv(\"data/candidates.txt\", \n",
    "                 encoding=\"utf-8\",\n",
    "                 header=None, sep='\\t',\n",
    "                quoting=csv.QUOTE_NONE)\n",
    "c_df.columns = ['candidate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateWithFreq = {}\n",
    "for word in c_df.candidate:\n",
    "    candidateWithFreq[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets_df.tweet:\n",
    "    tokens = TextBlob(tweet).words\n",
    "    for token in tokens:\n",
    "        if (token in candidateWithFreq): candidateWithFreq[token] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaaa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaaaaaaaaahhhhhhhhhhhh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        key  count\n",
       "0                                     aaaaa      1\n",
       "1                                aaaaaaaaaa      1\n",
       "2                               aaaaaaaaaaa      1\n",
       "3  aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa      1\n",
       "4                  aaaaaaaaaaaahhhhhhhhhhhh      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateWithFreq_df = pd.DataFrame.from_dict(candidateWithFreq, orient='index', columns = ['count']).reset_index().rename(columns = {'index': 'key'})\n",
    "candidateWithFreq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8459, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateWithFreq_df[candidateWithFreq_df['count'] > 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefixes and suffixes create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = {}\n",
    "suffixes = {}\n",
    "for word_index in range(len(dictionary)):\n",
    "    # ignore word only have 1 character\n",
    "    word = dictionary[word_index]\n",
    "    if (len(word) >= 2):\n",
    "        # add the word itself to the prefix and suffix\n",
    "        if (word in prefixes):\n",
    "            prefixes[word].append(word_index)\n",
    "        else:\n",
    "            prefixes[word] = [word_index]\n",
    "        if (word in suffixes):\n",
    "            suffixes[word].append(word_index)\n",
    "        else:\n",
    "            suffixes[word] = [word_index]\n",
    "            \n",
    "        # get prefix and suffix maps\n",
    "        for i in range(len(word) - 3):\n",
    "            pf = word[:i + 2]\n",
    "            sf = word[i + 2:]\n",
    "            if (pf in prefixes):\n",
    "                prefixes[pf].append(word_index)\n",
    "            else:\n",
    "                prefixes[pf] = [word_index]\n",
    "            if (sf in suffixes):\n",
    "                suffixes[sf].append(word_index)\n",
    "            else:\n",
    "                suffixes[sf] = [word_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look into blends.txt (BAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blends_df = pd.read_csv('data/blends.txt', \n",
    "                 encoding=\"utf-8\",\n",
    "                 header=None, sep='\\t',\n",
    "                quoting=csv.QUOTE_NONE)\n",
    "blends_df.columns = ['blend', 'pre', 'suf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>pre</th>\n",
       "      <th>suf</th>\n",
       "      <th>pre freq</th>\n",
       "      <th>suf freq</th>\n",
       "      <th>dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amtrak</td>\n",
       "      <td>amphibious</td>\n",
       "      <td>tractor</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bangel</td>\n",
       "      <td>buffy</td>\n",
       "      <td>angel</td>\n",
       "      <td>26</td>\n",
       "      <td>139</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bash</td>\n",
       "      <td>bat</td>\n",
       "      <td>mash</td>\n",
       "      <td>66</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beefaroni</td>\n",
       "      <td>beef</td>\n",
       "      <td>macaroni</td>\n",
       "      <td>184</td>\n",
       "      <td>13</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>belieber</td>\n",
       "      <td>believer</td>\n",
       "      <td>bieber</td>\n",
       "      <td>20</td>\n",
       "      <td>89</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       blend         pre       suf  pre freq  suf freq   dc\n",
       "0     amtrak  amphibious   tractor         1        21 -1.0\n",
       "1     bangel       buffy     angel        26       139  4.0\n",
       "2       bash         bat      mash        66        41  0.0\n",
       "3  beefaroni        beef  macaroni       184        13  7.5\n",
       "4   belieber    believer    bieber        20        89  3.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blends_df['pre freq'] = blends_df['pre'].apply(lambda x: dictWithFreq[x])\n",
    "blends_df['suf freq'] = blends_df['suf'].apply(lambda x: dictWithFreq[x])\n",
    "blends_df['dc'] = blends_df['blend'].apply(lambda x: getDC(x, prefixes, suffixes, 0.5))\n",
    "blends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blend</th>\n",
       "      <th>pre</th>\n",
       "      <th>suf</th>\n",
       "      <th>pre freq</th>\n",
       "      <th>suf freq</th>\n",
       "      <th>dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amtrak</td>\n",
       "      <td>amphibious</td>\n",
       "      <td>tractor</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>fayettenam</td>\n",
       "      <td>fayetteville</td>\n",
       "      <td>vietnam</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>jav</td>\n",
       "      <td>japanese</td>\n",
       "      <td>av</td>\n",
       "      <td>199</td>\n",
       "      <td>38</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>nor</td>\n",
       "      <td>not</td>\n",
       "      <td>or</td>\n",
       "      <td>18594</td>\n",
       "      <td>10693</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>yed</td>\n",
       "      <td>your</td>\n",
       "      <td>editor</td>\n",
       "      <td>24203</td>\n",
       "      <td>152</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>melatonin</td>\n",
       "      <td>melanin</td>\n",
       "      <td>serotonin</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>soca</td>\n",
       "      <td>soul</td>\n",
       "      <td>calypso</td>\n",
       "      <td>434</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>mar</td>\n",
       "      <td>martensite</td>\n",
       "      <td>aging</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>malaysia</td>\n",
       "      <td>malaya</td>\n",
       "      <td>asia</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>mahoosive</td>\n",
       "      <td>massive</td>\n",
       "      <td>huge</td>\n",
       "      <td>191</td>\n",
       "      <td>746</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>hir</td>\n",
       "      <td>him</td>\n",
       "      <td>her</td>\n",
       "      <td>3489</td>\n",
       "      <td>5853</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>medicaid</td>\n",
       "      <td>medical</td>\n",
       "      <td>aid</td>\n",
       "      <td>369</td>\n",
       "      <td>158</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>twitterati</td>\n",
       "      <td>twitter</td>\n",
       "      <td>literati</td>\n",
       "      <td>8630</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>hse</td>\n",
       "      <td>he</td>\n",
       "      <td>she</td>\n",
       "      <td>7812</td>\n",
       "      <td>5256</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>workaholic</td>\n",
       "      <td>work</td>\n",
       "      <td>alcoholic</td>\n",
       "      <td>6747</td>\n",
       "      <td>32</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>whatsapp</td>\n",
       "      <td>what</td>\n",
       "      <td>app</td>\n",
       "      <td>16878</td>\n",
       "      <td>1033</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bit</td>\n",
       "      <td>binary</td>\n",
       "      <td>digit</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>wanksta</td>\n",
       "      <td>wannabe</td>\n",
       "      <td>gangsta</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>shag</td>\n",
       "      <td>shower</td>\n",
       "      <td>stag</td>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>vajazzle</td>\n",
       "      <td>vagina</td>\n",
       "      <td>bedazzle</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>vlog</td>\n",
       "      <td>video</td>\n",
       "      <td>blog</td>\n",
       "      <td>5939</td>\n",
       "      <td>4718</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>sexting</td>\n",
       "      <td>sex</td>\n",
       "      <td>texting</td>\n",
       "      <td>1001</td>\n",
       "      <td>169</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>limon</td>\n",
       "      <td>lime</td>\n",
       "      <td>lemon</td>\n",
       "      <td>56</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sext</td>\n",
       "      <td>sex</td>\n",
       "      <td>text</td>\n",
       "      <td>1001</td>\n",
       "      <td>861</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>prissy</td>\n",
       "      <td>prim</td>\n",
       "      <td>fussy</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>macon</td>\n",
       "      <td>mutton</td>\n",
       "      <td>bacon</td>\n",
       "      <td>1</td>\n",
       "      <td>298</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>pleather</td>\n",
       "      <td>plastic</td>\n",
       "      <td>leather</td>\n",
       "      <td>159</td>\n",
       "      <td>94</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>jelena</td>\n",
       "      <td>justin</td>\n",
       "      <td>selena</td>\n",
       "      <td>232</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>nizzle</td>\n",
       "      <td>nigga</td>\n",
       "      <td>izzle</td>\n",
       "      <td>1393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>motel</td>\n",
       "      <td>motor</td>\n",
       "      <td>hotel</td>\n",
       "      <td>44</td>\n",
       "      <td>568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>gaydar</td>\n",
       "      <td>gay</td>\n",
       "      <td>radar</td>\n",
       "      <td>618</td>\n",
       "      <td>54</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>screamo</td>\n",
       "      <td>scream</td>\n",
       "      <td>emo</td>\n",
       "      <td>119</td>\n",
       "      <td>61</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>shamwow</td>\n",
       "      <td>chamois</td>\n",
       "      <td>wow</td>\n",
       "      <td>2</td>\n",
       "      <td>2450</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>fivehead</td>\n",
       "      <td>five</td>\n",
       "      <td>forehead</td>\n",
       "      <td>579</td>\n",
       "      <td>39</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dumpster</td>\n",
       "      <td>dump</td>\n",
       "      <td>dempster</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>sitcom</td>\n",
       "      <td>situation</td>\n",
       "      <td>comedy</td>\n",
       "      <td>197</td>\n",
       "      <td>274</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>shwasted</td>\n",
       "      <td>shitfaced</td>\n",
       "      <td>wasted</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>jewfro</td>\n",
       "      <td>jew</td>\n",
       "      <td>afro</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>dickhole</td>\n",
       "      <td>dick</td>\n",
       "      <td>asshole</td>\n",
       "      <td>398</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beefaroni</td>\n",
       "      <td>beef</td>\n",
       "      <td>macaroni</td>\n",
       "      <td>184</td>\n",
       "      <td>13</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>longrange</td>\n",
       "      <td>long</td>\n",
       "      <td>range</td>\n",
       "      <td>2730</td>\n",
       "      <td>114</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>sexcapade</td>\n",
       "      <td>sex</td>\n",
       "      <td>escapade</td>\n",
       "      <td>1001</td>\n",
       "      <td>5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>microcomputer</td>\n",
       "      <td>software</td>\n",
       "      <td>0</td>\n",
       "      <td>631</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>fucktard</td>\n",
       "      <td>fucking</td>\n",
       "      <td>retard</td>\n",
       "      <td>827</td>\n",
       "      <td>18</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>crangrape</td>\n",
       "      <td>cranberry</td>\n",
       "      <td>grape</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>newbie</td>\n",
       "      <td>new</td>\n",
       "      <td>baby</td>\n",
       "      <td>19383</td>\n",
       "      <td>2008</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>fruitopia</td>\n",
       "      <td>fruit</td>\n",
       "      <td>utopia</td>\n",
       "      <td>171</td>\n",
       "      <td>13</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>parkway</td>\n",
       "      <td>park</td>\n",
       "      <td>railway</td>\n",
       "      <td>884</td>\n",
       "      <td>5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>payola</td>\n",
       "      <td>pay</td>\n",
       "      <td>victrola</td>\n",
       "      <td>1277</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>governator</td>\n",
       "      <td>governor</td>\n",
       "      <td>terminator</td>\n",
       "      <td>107</td>\n",
       "      <td>23</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>webinar</td>\n",
       "      <td>web</td>\n",
       "      <td>seminar</td>\n",
       "      <td>1631</td>\n",
       "      <td>146</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>webisode</td>\n",
       "      <td>web</td>\n",
       "      <td>episode</td>\n",
       "      <td>1631</td>\n",
       "      <td>641</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>hollyweird</td>\n",
       "      <td>hollywood</td>\n",
       "      <td>weird</td>\n",
       "      <td>392</td>\n",
       "      <td>675</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>fooligan</td>\n",
       "      <td>fool</td>\n",
       "      <td>hooligan</td>\n",
       "      <td>317</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>escalator</td>\n",
       "      <td>escalate</td>\n",
       "      <td>elevator</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bootylicious</td>\n",
       "      <td>booty</td>\n",
       "      <td>delicious</td>\n",
       "      <td>119</td>\n",
       "      <td>370</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>overstand</td>\n",
       "      <td>over</td>\n",
       "      <td>understand</td>\n",
       "      <td>5451</td>\n",
       "      <td>597</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>planeteer</td>\n",
       "      <td>planet</td>\n",
       "      <td>volunteer</td>\n",
       "      <td>237</td>\n",
       "      <td>142</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>popsicle</td>\n",
       "      <td>pop</td>\n",
       "      <td>icicle</td>\n",
       "      <td>437</td>\n",
       "      <td>0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>wiki</td>\n",
       "      <td>encyclopedia</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            blend            pre           suf  pre freq  suf freq   dc\n",
       "0          amtrak     amphibious       tractor         1        21 -1.0\n",
       "36     fayettenam   fayetteville       vietnam        24        50 -1.0\n",
       "71            jav       japanese            av       199        38 -1.0\n",
       "107           nor            not            or     18594     10693 -1.0\n",
       "181           yed           your        editor     24203       152 -1.0\n",
       "88      melatonin        melanin     serotonin         2         3 -1.0\n",
       "146          soca           soul       calypso       434         7 -1.0\n",
       "85            mar     martensite         aging         0        90 -1.0\n",
       "82       malaysia         malaya          asia         1       105 -1.0\n",
       "81      mahoosive        massive          huge       191       746 -1.0\n",
       "61            hir            him           her      3489      5853 -1.0\n",
       "86       medicaid        medical           aid       369       158 -1.0\n",
       "167    twitterati        twitter      literati      8630         1 -1.0\n",
       "65            hse             he           she      7812      5256 -1.0\n",
       "178    workaholic           work     alcoholic      6747        32 -1.0\n",
       "175      whatsapp           what           app     16878      1033 -1.0\n",
       "5             bit         binary         digit         6         7 -1.0\n",
       "172       wanksta        wannabe       gangsta        21        73 -1.0\n",
       "124          shag         shower          stag       533         5 -1.0\n",
       "168      vajazzle         vagina      bedazzle        63         1 -1.0\n",
       "171          vlog          video          blog      5939      4718 -1.0\n",
       "123       sexting            sex       texting      1001       169  0.0\n",
       "77          limon           lime         lemon        56        81  0.0\n",
       "122          sext            sex          text      1001       861  0.0\n",
       "117        prissy           prim         fussy         1         7  0.0\n",
       "80          macon         mutton         bacon         1       298  0.0\n",
       "112      pleather        plastic       leather       159        94  0.0\n",
       "73         jelena         justin        selena       232        62  0.0\n",
       "106        nizzle          nigga         izzle      1393         1  0.0\n",
       "98          motel          motor         hotel        44       568  0.0\n",
       "..            ...            ...           ...       ...       ...  ...\n",
       "49         gaydar            gay         radar       618        54  7.0\n",
       "119       screamo         scream           emo       119        61  7.0\n",
       "125       shamwow        chamois           wow         2      2450  7.0\n",
       "39       fivehead           five      forehead       579        39  7.0\n",
       "32       dumpster           dump      dempster        53         1  7.0\n",
       "133        sitcom      situation        comedy       197       274  7.0\n",
       "131      shwasted      shitfaced        wasted         0       187  7.0\n",
       "74         jewfro            jew          afro        19        18  7.5\n",
       "30       dickhole           dick       asshole       398       100  7.5\n",
       "3       beefaroni           beef      macaroni       184        13  7.5\n",
       "78      longrange           long         range      2730       114  7.5\n",
       "120     sexcapade            sex      escapade      1001         5  7.5\n",
       "93      microsoft  microcomputer      software         0       631  7.5\n",
       "45       fucktard        fucking        retard       827        18  7.5\n",
       "25      crangrape      cranberry         grape        46        47  7.5\n",
       "105        newbie            new          baby     19383      2008  7.5\n",
       "44      fruitopia          fruit        utopia       171        13  7.5\n",
       "109       parkway           park       railway       884         5  7.5\n",
       "110        payola            pay      victrola      1277         0  7.5\n",
       "52     governator       governor    terminator       107        23  8.0\n",
       "173       webinar            web       seminar      1631       146  8.0\n",
       "174      webisode            web       episode      1631       641  8.0\n",
       "62     hollyweird      hollywood         weird       392       675  8.0\n",
       "41       fooligan           fool      hooligan       317         0  8.0\n",
       "34      escalator       escalate      elevator         4        87  8.0\n",
       "8    bootylicious          booty     delicious       119       370  8.0\n",
       "108     overstand           over    understand      5451       597  8.5\n",
       "111     planeteer         planet     volunteer       237       142  8.5\n",
       "115      popsicle            pop        icicle       437         0  8.5\n",
       "177     wikipedia           wiki  encyclopedia        31         6  9.0\n",
       "\n",
       "[183 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blends_df.sort_values(by='dc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre freq</th>\n",
       "      <th>suf freq</th>\n",
       "      <th>dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1966.000000</td>\n",
       "      <td>436.413580</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8729.247772</td>\n",
       "      <td>1814.822167</td>\n",
       "      <td>3.159822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>162.500000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>861.750000</td>\n",
       "      <td>271.250000</td>\n",
       "      <td>6.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>101460.000000</td>\n",
       "      <td>21578.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pre freq      suf freq          dc\n",
       "count     162.000000    162.000000  162.000000\n",
       "mean     1966.000000    436.413580    3.000000\n",
       "std      8729.247772   1814.822167    3.159822\n",
       "min         0.000000      0.000000    0.000000\n",
       "25%        21.250000     18.000000    0.000000\n",
       "50%       162.500000     81.000000    2.500000\n",
       "75%       861.750000    271.250000    6.875000\n",
       "max    101460.000000  21578.000000    9.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blends_df[blends_df['dc'] >= 0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blend detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateWithFreq_df['True blend'] = candidateWithFreq_df['key'].apply(lambda x: x in blends_df.blend.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>count</th>\n",
       "      <th>True blend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaaaaaaaaahhhhhhhhhhhh</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        key  count  True blend\n",
       "0                                     aaaaa      1       False\n",
       "1                                aaaaaaaaaa      1       False\n",
       "2                               aaaaaaaaaaa      1       False\n",
       "3  aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa      1       False\n",
       "4                  aaaaaaaaaaaahhhhhhhhhhhh      1       False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateWithFreq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a5d974ca9110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m## freq > 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcandidateWithFreq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mrealdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefixes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrealdc\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrealdc\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0misBlend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misBlend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-56cfe78b574c>\u001b[0m in \u001b[0;36mgetDC\u001b[0;34m(blendWord, prefixes, suffixes, w1)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pre-suf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblendWord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcandidates_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5066\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5067\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4350\u001b[0m         \u001b[0;31m# Things like `Series._get_value` (via .at) pass the EA directly here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4351\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4352\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mExtensionArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4353\u001b[0m             \u001b[0;31m# GH 20882, 21257\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4354\u001b[0m             \u001b[0;31m# Unify Index and ExtensionArray treatment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dc = []\n",
    "for index, row in candidateWithFreq_df.iterrows():\n",
    "    isBlend = False\n",
    "#     print(\"Processing: \" + row['key'])\n",
    "    ## freq > 1\n",
    "    if (candidateWithFreq[row['key']] > 10):\n",
    "        realdc = getDC(row['key'], prefixes, suffixes, 0.5)\n",
    "        if (realdc >= 0 and realdc <= 9): isBlend = True\n",
    "    dc.append(isBlend)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateWithFreq_df[\"Prd't Blend\"] = dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for index, row in candidateWithFreq_df.iterrows():\n",
    "    if (row['True blend'] == True and row[\"Prd't Blend\"] == True):\n",
    "        TP += 1\n",
    "    if (row['True blend'] == False and row[\"Prd't Blend\"] == True):\n",
    "        FP += 1\n",
    "    if (row['True blend'] == True and row[\"Prd't Blend\"] == False):  \n",
    "        FN += 1\n",
    "    if (row['True blend'] == False and row[\"Prd't Blend\"] == False):  \n",
    "        TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "F1 = 2 * (precision * Recall) / (precision + Recall)\n",
    "print(TP, TN, FP, FN)\n",
    "print(precision, Recall, accuracy, F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dc 10 N 20\n",
    "37 15794 739 114\n",
    "0.04768041237113402 0.24503311258278146 0.9488731719012228 0.07982740021574973\n",
    "\n",
    "dc 10 N 10\n",
    "55 15228 1305 96\n",
    "0.04044117647058824 0.36423841059602646 0.9160273315751618 0.07279947054930509"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">2\n",
    "74 13912 2621 77\n",
    "0.027458256029684602 0.4900662251655629 0.8382881802924959 0.05200281096275475\n",
    "\n",
    ">1\n",
    "83 13055 3478 68\n",
    "0.02330805953383881 0.5496688741721855 0.7874610405178615 0.04471982758620689\n",
    "\n",
    ">0\n",
    "96 10770 5763 55\n",
    "0.01638504864311316 0.6357615894039735 0.6512826660273315 0.031946755407653904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### component detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blend</th>\n",
       "      <th>Pre</th>\n",
       "      <th>Suf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amtrak</td>\n",
       "      <td>amphibious</td>\n",
       "      <td>tractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bangel</td>\n",
       "      <td>buffy</td>\n",
       "      <td>angel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bash</td>\n",
       "      <td>bat</td>\n",
       "      <td>mash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beefaroni</td>\n",
       "      <td>beef</td>\n",
       "      <td>macaroni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>belieber</td>\n",
       "      <td>believer</td>\n",
       "      <td>bieber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Blend         Pre       Suf\n",
       "0     amtrak  amphibious   tractor\n",
       "1     bangel       buffy     angel\n",
       "2       bash         bat      mash\n",
       "3  beefaroni        beef  macaroni\n",
       "4   belieber    believer    bieber"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "test = pd.read_csv(\"data/blends.txt\", \n",
    "                 encoding=\"utf-8\",\n",
    "                 header=None, sep='\\t',\n",
    "                quoting=csv.QUOTE_NONE)\n",
    "test.columns = ['Blend', 'Pre', 'Suf']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: amtrak\n",
      "Processing: bangel\n",
      "Processing: bash\n",
      "Processing: beefaroni\n",
      "Processing: belieber\n",
      "Processing: bit\n",
      "Processing: blaxican\n",
      "Processing: bollywood\n",
      "Processing: bootylicious\n",
      "Processing: botox\n",
      "Processing: brainiac\n",
      "Processing: bromance\n",
      "Processing: brunch\n",
      "Processing: buppie\n",
      "Processing: californication\n",
      "Processing: cama\n",
      "Processing: camcorder\n",
      "Processing: cheeseburger\n",
      "Processing: chillax\n",
      "Processing: clash\n",
      "Processing: clink\n",
      "Processing: clois\n",
      "Processing: cosplay\n",
      "Processing: crackberry\n",
      "Processing: cranapple\n",
      "Processing: crangrape\n",
      "Processing: crooklyn\n",
      "Processing: crunk\n",
      "Processing: daycation\n",
      "Processing: dentro\n",
      "Processing: dickhole\n",
      "Processing: dout\n",
      "Processing: dumpster\n",
      "Processing: ebonics\n",
      "Processing: escalator\n",
      "Processing: fantabulous\n",
      "Processing: fayettenam\n",
      "Processing: fedex\n",
      "Processing: femcee\n",
      "Processing: fivehead\n",
      "Processing: flunk\n",
      "Processing: fooligan\n",
      "Processing: frappuccino\n",
      "Processing: frohawk\n",
      "Processing: fruitopia\n",
      "Processing: fucktard\n",
      "Processing: fugly\n",
      "Processing: funemployment\n",
      "Processing: futch\n",
      "Processing: gaydar\n",
      "Processing: ginormous\n",
      "Processing: glambert\n",
      "Processing: governator\n",
      "Processing: gravatar\n",
      "Processing: greige\n",
      "Processing: gunk\n",
      "Processing: hangry\n",
      "Processing: harmony\n",
      "Processing: henny\n",
      "Processing: herstory\n",
      "Processing: hijack\n",
      "Processing: hir\n",
      "Processing: hollyweird\n",
      "Processing: homeboy\n",
      "Processing: hotlanta\n",
      "Processing: hse\n",
      "Processing: hunty\n",
      "Processing: infomercial\n",
      "Processing: irregardless\n",
      "Processing: ital\n",
      "Processing: itouch\n",
      "Processing: jav\n",
      "Processing: jedward\n",
      "Processing: jelena\n",
      "Processing: jewfro\n",
      "Processing: jorts\n",
      "Processing: kendra\n",
      "Processing: limon\n",
      "Processing: longrange\n",
      "Processing: macbook\n",
      "Processing: macon\n",
      "Processing: mahoosive\n",
      "Processing: malaysia\n",
      "Processing: manny\n",
      "Processing: manwich\n",
      "Processing: mar\n",
      "Processing: medicaid\n",
      "Processing: meggings\n",
      "Processing: melatonin\n",
      "Processing: meld\n",
      "Processing: merm\n",
      "Processing: metaverse\n",
      "Processing: metroplex\n",
      "Processing: microsoft\n",
      "Processing: mimsy\n",
      "Processing: minja\n",
      "Processing: modem\n",
      "Processing: moped\n",
      "Processing: motel\n",
      "Processing: motown\n",
      "Processing: mozilla\n",
      "Processing: muppet\n",
      "Processing: naco\n",
      "Processing: neither\n",
      "Processing: netbook\n",
      "Processing: newbie\n",
      "Processing: nizzle\n",
      "Processing: nor\n",
      "Processing: overstand\n",
      "Processing: parkway\n",
      "Processing: payola\n",
      "Processing: planeteer\n",
      "Processing: pleather\n",
      "Processing: podcast\n",
      "Processing: poofy\n",
      "Processing: popsicle\n",
      "Processing: prettiful\n",
      "Processing: prissy\n",
      "Processing: purrfect\n",
      "Processing: screamo\n",
      "Processing: sexcapade\n",
      "Processing: sexpert\n",
      "Processing: sext\n",
      "Processing: sexting\n",
      "Processing: shag\n",
      "Processing: shamwow\n",
      "Processing: shamy\n",
      "Processing: shart\n",
      "Processing: shero\n",
      "Processing: shim\n",
      "Processing: shortrange\n",
      "Processing: shwasted\n",
      "Processing: sial\n",
      "Processing: sitcom\n",
      "Processing: skank\n",
      "Processing: skeezy\n",
      "Processing: skort\n",
      "Processing: skunk\n",
      "Processing: slithy\n",
      "Processing: slore\n",
      "Processing: smash\n",
      "Processing: smexy\n",
      "Processing: smush\n",
      "Processing: snarf\n",
      "Processing: snark\n",
      "Processing: snazzy\n",
      "Processing: soca\n",
      "Processing: sony\n",
      "Processing: spanglish\n",
      "Processing: spork\n",
      "Processing: spunk\n",
      "Processing: stan\n",
      "Processing: steez\n",
      "Processing: sunlight\n",
      "Processing: telethon\n",
      "Processing: teme\n",
      "Processing: tenderoni\n",
      "Processing: texting\n",
      "Processing: thon\n",
      "Processing: travelocity\n",
      "Processing: tribeca\n",
      "Processing: tween\n",
      "Processing: tweep\n",
      "Processing: tweeple\n",
      "Processing: tweetheart\n",
      "Processing: tweetup\n",
      "Processing: twerk\n",
      "Processing: twitterati\n",
      "Processing: vajazzle\n",
      "Processing: verizon\n",
      "Processing: vitamin\n",
      "Processing: vlog\n",
      "Processing: wanksta\n",
      "Processing: webinar\n",
      "Processing: webisode\n",
      "Processing: whatsapp\n",
      "Processing: wigger\n",
      "Processing: wikipedia\n",
      "Processing: workaholic\n",
      "Processing: wuss\n",
      "Processing: wussy\n",
      "Processing: yed\n",
      "Processing: yello\n"
     ]
    }
   ],
   "source": [
    "pP = []\n",
    "sP = []\n",
    "for index, row in test.iterrows():\n",
    "#     print(\"Processing: \" + row['Blend'])\n",
    "    pSet, sSet = getTopNSufComponent(row['Blend'], prefixes, suffixes, 1, 0.75)\n",
    "    pP.append(row['Pre'] in pSet)\n",
    "    sP.append(row['Suf'] in sSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09289617486338798 0.3005464480874317\n"
     ]
    }
   ],
   "source": [
    "countp = 0\n",
    "counts = 0\n",
    "for i in range(len(pP)):\n",
    "    if (pP[i] == True):\n",
    "        countp += 1\n",
    "    if (sP[i] == True):\n",
    "        counts += 1\n",
    "\n",
    "print(countp / len(pP), counts / len(sP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank 1\n",
    "0.0 0.08743169398907104 0.2896174863387978\n",
    "0.5 0.08743169398907104 0.3005464480874317"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank 5\n",
    "0.15300546448087432 0.5027322404371585"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
